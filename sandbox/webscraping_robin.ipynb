{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8a151b",
   "metadata": {},
   "source": [
    "# Webscraping - A Notebook from Robin\n",
    "In this notebook, I'll explore ways of scrape the necessary information we would like to scrape on\n",
    "\n",
    "* HuggingFace Leaderboards\n",
    "* LLM-stats.com\n",
    "For this purpose, I'll use python libraries such as BeautifulSoup and MechanicalSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181d6e1",
   "metadata": {
    "title": "[library]"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import mechanicalsoup as ms\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9c770",
   "metadata": {},
   "source": [
    "[Hugging Face Open Leadboards](#https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/) has a faily simply structure.\n",
    "It is a simple page with a table.\n",
    "This table is scrollable and contains all the available models and their information.\n",
    "Alternatively, there is also a search bar, allowing filtering of the table.# Other advanced filters are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e185e4",
   "metadata": {},
   "source": [
    "Let's first create a `SatefulBrowser` instance from `MechanicalSoup` enabling interaction with the websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db83e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = ms.StatefulBrowser(soup_config={\"features\": \"lxml\"}, raise_on_404=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4546bb",
   "metadata": {
    "title": "[markown]"
   },
   "outputs": [],
   "source": [
    "# Then, we'll open the Hugging Face Leaderboards page.\n",
    "# We can use the search bar feature directly in the URL by adding `?search=[model_name]`.\n",
    "# Alternatively, interacting with the filters would require library handling dynamic websites such as `Selenium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/\"\n",
    "browser.open(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b04881",
   "metadata": {},
   "source": [
    "Now, some features of the website is dynamic.\n",
    "Hence, we'll set up Selenium to interact with the webpage dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe10d6",
   "metadata": {},
   "source": [
    "First, we'll set up the driver and make it go on the desired webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efae523",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df3ecb9",
   "metadata": {},
   "source": [
    "Since the information we're looking at are stored nested inside a HTML 'table' tag, we can first locate this element and then look at what is inside rescursively.\n",
    "However, this same table is inside an iframe, an interactive container, which we will need to switch to beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table\n",
    "iframe = driver.find_element(By.XPATH, '//*[@id=\"iFrameResizer0\"]')\n",
    "driver.switch_to.frame(iframe)\n",
    "table = driver.find_element(By.TAG_NAME, \"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077abab2",
   "metadata": {},
   "source": [
    "HTML table contains a 'thead' tag element, in which the information about the headers are contains.\n",
    "In our case, 'thead' contains a 'th' element, which contains a 'p' element.\n",
    "Said 'p' element contains the name of the desired column.\n",
    "\n",
    "Now that we know this, we can just look for all 'p' element inside each 'th' elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa3029",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "thead = table.find_element(By.TAG_NAME, \"thead\")\n",
    "colnames = [\n",
    "    th.find_element(By.TAG_NAME, \"p\").text\n",
    "    for th in thead.find_elements(By.TAG_NAME, \"th\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20a958",
   "metadata": {},
   "source": [
    "Next up are the rows.\n",
    "The rows are contained inside a 'tbody' element, while each the information contained inside each row are inside a 'tr' element.\n",
    "Inside each 'tr', a list of 'td' is placed, each contained a 'p' element for the cell text.\n",
    "\n",
    "A small difference is with the model name, which actually are link. This link is the first link of the row, hence we can just look for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "row = rows[0]\n",
    "for row in rows:\n",
    "    obs = [p.text for p in row.find_elements(By.TAG_NAME, \"p\")]\n",
    "    obs.insert(2, row.find_element(By.TAG_NAME, \"a\").text)\n",
    "    print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e7fc7",
   "metadata": {},
   "source": [
    "Now that we have a framework for scraping all the information inside the table that we want, we only need to store it.\n",
    "Since the information is gathered row-wise, we'll write it sequentially as a `CSV` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10e0a0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with open(\"hf_leaderboard.csv\", \"w\") as f:\n",
    "    # Write columns or variable names\n",
    "    colnames.append(\"\\n\")\n",
    "    f.write(\",\".join(colnames[1:]))\n",
    "\n",
    "    # Loop over each row and write them sequentially\n",
    "    for i, row in enumerate(rows):\n",
    "        obs = [p.text for p in row.find_elements(By.TAG_NAME, \"p\")]\n",
    "        obs.insert(2, row.find_element(By.TAG_NAME, \"a\").text)\n",
    "        obs.append(\"\\n\")\n",
    "        f.write(\",\".join(obs))\n",
    "        print(f\"Row {i} has been written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3bc62",
   "metadata": {},
   "source": [
    "The last thing we need to take care of is the fact that we need to scroll down the table to have the rest of the models.\n",
    "However, I had trouble with the scrolling, I'll just use the 'search' bar mechanism to filter the table for the model I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_meta = pd.read_csv(\"huggingface_llm_metadata.csv\")\n",
    "models = hf_meta.modelId.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd509d",
   "metadata": {},
   "source": [
    "The first step will be to already write the columns name inside the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari()\n",
    "url = \"https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "iframe = driver.find_element(By.XPATH, '//*[@id=\"iFrameResizer0\"]')\n",
    "driver.switch_to.frame(iframe)\n",
    "with open(\"hf_leaderboard.csv\", \"w\") as f:\n",
    "    table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "    thead = table.find_element(By.TAG_NAME, \"thead\")\n",
    "    colnames = [\n",
    "        th.find_element(By.TAG_NAME, \"p\").text\n",
    "        for th in thead.find_elements(By.TAG_NAME, \"th\")\n",
    "    ]\n",
    "    # Write columns or variable names\n",
    "    colnames.append(\"\\n\")\n",
    "    f.write(\",\".join(colnames[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71da71",
   "metadata": {},
   "source": [
    "Now that we have the column names written, we can append the rest of the rows to it.\n",
    "\n",
    "**Remarks**: I incountered some issue when switching pages.\n",
    "Hence, I had to close the driver and open it again every time.\n",
    "Additionnaly, it is necessary to let the driver time to open and scrape things. Hence incorporating waiting time is of uptmost importance, otherwise it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ac57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hf_leaderboard.csv\", \"a\") as f:\n",
    "    for model in models:\n",
    "        driver = webdriver.Safari()\n",
    "        time.sleep(5)\n",
    "        # Open the webpage with the filter\n",
    "        driver.get(url + f\"?search={model}\")\n",
    "        time.sleep(5)\n",
    "        # Make sure that the page is completely loaded.\n",
    "        # Switch to the corresponding iFrame\n",
    "        iframe = driver.find_element(By.XPATH, '//*[@id=\"iFrameResizer0\"]')\n",
    "        driver.switch_to.frame(iframe)\n",
    "        # Check for unavailable model on the website\n",
    "        try:\n",
    "            # Get the table element\n",
    "            table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "        except NoSuchElementException:\n",
    "            driver.close()\n",
    "            continue\n",
    "        # Get the body element\n",
    "        tbody = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "        # Get the first row, so the first model appearing in the search\n",
    "        row = tbody.find_element(By.TAG_NAME, \"tr\")\n",
    "        # Get all the information from the row\n",
    "        obs = [p.text for p in row.find_elements(By.TAG_NAME, \"p\")]\n",
    "        # Make sure to also get the model name, which is a link\n",
    "        obs.insert(2, row.find_element(By.TAG_NAME, \"a\").text)\n",
    "        # Write everything inside the CSV file as a new row.\n",
    "        obs.append(\"\\n\")\n",
    "        f.write(\",\".join(obs))\n",
    "        driver.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
